mutate(is_hit = train_small$is_hit)
# 2. Train a small k-NN on those two PCs
set.seed(123)
pca_knn <- train(is_hit ~ ., data = train_pca,
method = "knn",
tuneGrid = data.frame(k = knn_fit$bestTune$k))
# 3. Predict on a grid for a smooth boundary
grid <- expand.grid(PC1 = seq(min(train_pca$PC1), max(train_pca$PC1), length = 200),
PC2 = seq(min(train_pca$PC2), max(train_pca$PC2), length = 200))
grid$pred <- predict(pca_knn, newdata = grid)
ggplot() +
geom_tile(data = grid, aes(PC1, PC2, fill = pred), alpha = 0.3) +
geom_point(data = train_pca, aes(PC1, PC2, colour = is_hit), size = 1) +
scale_fill_manual(values = c("0" = "grey80", "1" = "lightpink")) +
scale_colour_manual(values = c("0" = "grey20", "1" = "red3")) +
labs(title = "k-NN decision regions in PC space",
fill = "Predicted",
colour = "Actual") +
theme_minimal()
# cross-validation set up
dt_ctrl <- trainControl(
method          = "cv",
number          = 5,
classProbs      = TRUE,
summaryFunction = twoClassSummary,
sampling        = "down",
savePredictions = "final"
)
tree_grid <- expand.grid(
cp = 10 ^ seq(-4, -1, length.out = 10)
)
set.seed(123)
tree_fit <- train(is_hit ~ danceability + energy + loudness + valence +
tempo + speechiness + liveness + instrumentalness +
acousticness + duration_ms,
data = train,
method = "rpart",      # allows maxdepth tuning
trControl = dt_ctrl,
tuneGrid  = tree_grid,
metric    = "ROC",
control = rpart.control(cp = 0,
minsplit = 2,
minbucket = 1)
)
# 1. Build a PCA for visualisation only
pcs <- prcomp(train_small %>%
select(danceability, energy, loudness, valence,
tempo, speechiness, liveness, instrumentalness,
acousticness, duration_ms),
scale. = TRUE)
# 1. Build a PCA for visualisation only
pcs <- prcomp(train_small %>%
select(danceability, energy, loudness, valence,
tempo, speechiness, liveness, instrumentalness,
acousticness, duration_ms),
scale. = TRUE)
train_pca <- as_tibble(pcs$x[, 1:2]) %>%
mutate(is_hit = train_small$is_hit)
# 2. Train a small k-NN on those two PCs
set.seed(123)
pca_knn <- train(is_hit ~ ., data = train_pca,
method = "knn",
tuneGrid = data.frame(k = knn_fit$bestTune$k))
# 3. Predict on a grid for a smooth boundary
grid <- expand.grid(PC1 = seq(min(train_pca$PC1), max(train_pca$PC1), length = 200),
PC2 = seq(min(train_pca$PC2), max(train_pca$PC2), length = 200))
grid$pred <- predict(pca_knn, newdata = grid)
ggplot() +
geom_tile(data = grid, aes(PC1, PC2, fill = pred), alpha = 0.3) +
geom_point(data = train_pca, aes(PC1, PC2, colour = is_hit), size = 1) +
scale_fill_manual(values = c("0" = "grey80", "1" = "lightpink")) +
scale_colour_manual(values = c("0" = "grey20", "1" = "red3")) +
labs(title = "k-NN decision regions in PC space",
fill = "Predicted",
colour = "Actual") +
theme_minimal()
cm_df <- as.data.frame(knn_cm$table)
names(cm_df) <- c("Predicted", "Actual", "Freq")
ggplot(cm_df, aes(Actual, Predicted, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), colour = "white", size = 5) +
scale_fill_gradient(low = "skyblue", high = "steelblue") +
theme_minimal() +
labs(title = "Confusion matrix for test data")
ggplot(knn_fit$results, aes(k, Accuracy)) +
geom_line() +
geom_point(size = 2) +
geom_vline(xintercept = knn_fit$bestTune$k,
linetype = "dashed") +
labs(title = "Cross-validated accuracy across k values",
x = "Number of neighbours (k)",
y = "Accuracy") +
theme_minimal()
pdf("decision_tree.pdf", width = 30, height = 15)
rpart.plot(
tree_fit$finalModel,
type  = 4,
extra = 104,
main  = "Best Decision Tree (cp tuned, down-sampled)"
)
dev.off()
pdf("decision_tree.pdf", width = 30, height = 15)
rpart.plot(
tree_fit$finalModel,
type  = 4,
extra = 104,
main  = "Best Decision Tree (cp tuned, down-sampled)"
)
dev.off()
library(rpart.plot)
rpart.plot(tree_fit$finalModel,
type  = 4,      # tidy boxes
extra = 104,    # show class and % of hits
main  = "Best Decision Tree (cp tuned, down-sampled)")
pdf("decision_tree.pdf", width = 30, height = 15)
rpart.plot(
tree_fit$finalModel,
type  = 4,
extra = 104,
main  = "Best Decision Tree (cp tuned, down-sampled)"
)
dev.off()
library(partykit)
install.packages("partykit")
library(partykit)
party_tree <- as.party(tree_fit$finalModel)
plot(party_tree, tp_args = list(id = FALSE))
install.packages("rattle")
library(rattle)
fancyRpartPlot(tree_fit$finalModel)
library(rattle)
fancyRpartPlot(tree_fit$finalModel)
View(rpart.plot(tree_fit$finalModel, main = "Best Decision Tree"))
View(fancyRpartPlot(tree_fit$finalModel))
fancyRpartPlot(tree_fit$finalModel)
# install.packages(c("partykit", "data.tree", "DiagrammeR"))
library(partykit)    # for as.party()
library(data.tree)   # for as.Node()
install.packages("data.tree")
install.packages("DiagrammeR")
# install.packages(c("partykit", "data.tree", "DiagrammeR"))
library(partykit)    # for as.party()
library(data.tree)   # for as.Node()
library(DiagrammeR)  # for render_graph()
# 1. turn your rpart into a party object
p_tree <- as.party(tree_fit$finalModel)
# 2. convert that into a data.tree structure
dt_tree <- as.Node(p_tree)
# 3. build a DiagrammeR graph from the data.tree
dg    <- ToDiagrammeRGraph(dt_tree)
# 4. render in Viewer
render_graph(dg)
cm_df <- as.data.frame(knn_cm$table)
names(cm_df) <- c("Predicted", "Actual", "Freq")
ggplot(cm_df, aes(Actual, Predicted, fill = Freq)) +
geom_tile() +
geom_text(aes(label = Freq), colour = "white", size = 5) +
scale_fill_gradient(low = "skyblue", high = "steelblue") +
theme_minimal() +
labs(title = "Confusion matrix for test data")
# METHOD 2: categorical classification models
# CROSS-VALIDATION CONTROL
knn_ctrl <- trainControl(method = "cv",
number = 5,
savePredictions = "final")
# kNN  (tuning k)
set.seed(123)
knn_grid <- expand.grid(k = seq(3, 25, by = 2))
knn_fit <- train(is_hit ~ danceability + energy + loudness + valence +
tempo + speechiness + liveness + instrumentalness +
acousticness + duration_ms,
data = train_small,
method = "knn",
trControl = knn_ctrl,
tuneGrid  = knn_grid,
metric    = "Accuracy")
# best k and cross-validated accuracy
print(knn_fit$bestTune)
print(max(knn_fit$results$Accuracy))
# test-set accuracy
knn_pred <- predict(knn_fit, newdata = test)
knn_cm   <- confusionMatrix(knn_pred, test$is_hit, positive = "hit")
cat("\nTest accuracy (k-NN):",
round(knn_cm$overall["Accuracy"], 3), "\n")
library(dplyr)
library(tidyr)
library(ggplot2)
library(FactoMineR)   # For PCA computation
library(factoextra)   # For PCA visualization
library(cluster)
spotify_data <- read.csv("~/Downloads/SpotifyFeatures.csv")
library(dplyr)
library(tidyr)
library(ggplot2)
library(FactoMineR)   # For PCA computation
library(factoextra)   # For PCA visualization
library(cluster)
#import dataset
spotify_data <- read.csv("~/Downloads/SpotifyFeatures.csv")
#import dataset
spotify_data <- read.csv("~/Downloads/SpotifyFeatures.csv")
library(dplyr)
library(tidyr)
library(ggplot2)
library(FactoMineR)   # For PCA computation
library(factoextra)   # For PCA visualization
library(cluster)
#import dataset
spotify_data <- read.csv("SpotifyFeatures.csv")
dim(spotify_data)
View(spotify_data)
#check for missing values:
sum(is.na(spotify_data))
#check for duplicated data:
sum(duplicated(spotify_data))
#after viewing the spotify data, although there are no duplicates
#it seems that when a song falls into multiple genres, it becomes a repeated
#entry with only the genre different. This could skew the other attributes as they
#are duplicated. To fix this issue, we can one hot encode all of the genres.
#Although this will increase the dimensionality of our dataset by 27, it will
#be a much cleaner dataset, and we can always use PCA to reduce the dimensionality.
genre_dummies <- model.matrix(~ genre - 1, data = spotify_data)
spotify_data <- cbind(spotify_data[, -which(names(spotify_data) == "genre")], genre_dummies)
duplicates_count <- spotify_data %>%
group_by(track_id, track_name, artist_name) %>%
tally() %>%
filter(n > 1)
#amount of duplicates we will reduce
nrow(duplicates_count)
spotify_data <- spotify_data %>%
group_by(track_id, track_name, artist_name, key, mode, time_signature) %>%
summarise(across(where(is.numeric), ~ ifelse(all(. %in% c(0, 1)), max(.), mean(.))), .groups = "drop")
genre_cols <- grep("^genre", names(spotify_data), value = TRUE)
new_names <- setNames(paste0("genre: ", sub("^genre", "", genre_cols)), genre_cols)
names(spotify_data)[names(spotify_data) %in% genre_cols] <- new_names
View(spotify_data)
col1 <- "genre: Children's Music"
col2 <- "genre: Childrenâ€™s Music"
spotify_data[[col1]] <- pmax(
spotify_data[[col1]],
spotify_data[[col2]],
na.rm = TRUE
)
spotify_data[[col2]] <- NULL
dim(spotify_data)
#Explore the data
non_genre_cols <- spotify_data %>%
select(-starts_with("genre:")) %>%
select(-artist_name, -track_id, -track_name)
# 2. Go through each column
for (col in names(non_genre_cols)) {
cat("\n============================================================\n")
cat("Summary for:", col, "\n")
# Numeric columns
if (is.numeric(non_genre_cols[[col]])) {
# Plot histogram
hist(non_genre_cols[[col]],
main = paste("Histogram of", col),
xlab = col,
col = "skyblue",
breaks = 30)
# Print basic descriptive statistics
cat("Min:", min(non_genre_cols[[col]], na.rm = TRUE), "\n")
cat("Max:", max(non_genre_cols[[col]], na.rm = TRUE), "\n")
cat("Mean:", mean(non_genre_cols[[col]], na.rm = TRUE), "\n")
# Categorical columns
} else {
# Count categories
counts <- table(non_genre_cols[[col]])
# Bar plot for counts
barplot(counts,
main = paste("Bar Plot of", col),
xlab = col,
ylab = "Count",
col = "skyblue",
las = 2)  # rotate axis labels for readability
# Also print counts for good measure
print(counts)
}
cat("============================================================\n")
}
genre_cols <- grep("^genre: ", names(spotify_data), value = TRUE)
# 2. Sum across each genre column to get counts
genre_counts <- spotify_data %>%
select(all_of(genre_cols)) %>%
summarise(across(everything(), sum)) %>%
pivot_longer(cols = everything(), names_to = "Genre", values_to = "Count") %>%
arrange(desc(Count))
# 3. View the counts table
print(genre_counts)
# 4. Plot the counts
barplot(height = genre_counts$Count,
names.arg = gsub("genre: ", "", genre_counts$Genre), # Remove 'genre: ' prefix for display
las = 2,          # Rotate x-axis labels
col = "skyblue",
main = "Song Counts by Genre",
xlab = "Genre",
ylab = "Number of Songs",
cex.names = 0.7)
hist(spotify_data$duration_ms / 60000,
main = "Histogram of duration_ms in minutes",
xlab = "Duration (min)",
col = "skyblue",
breaks = 50,
xlim = c(0, 10))
# 1. Create one-hot encodings for key, mode, and time_signature
key_dummies <- model.matrix(~ key - 1, data = spotify_data)
mode_dummies <- model.matrix(~ mode - 1, data = spotify_data)
time_signature_dummies <- model.matrix(~ time_signature - 1, data = spotify_data)
# Question 2: Can we accurately predict whether a song becomes a hit?
library(tidyverse)
library(caret)
library(rpart)
library(xgboost)
library(pROC)
library(ranger)
library(rpart.plot)
library(pROC)
# create my own dataset to use for this analysis
enoch_df <- spotify_data
# creating "is_hit" column by calculating 90th percentile of popularity
hit_threshold <- quantile(enoch_df$popularity, probs = 0.90)
# create binary target
enoch_df <- enoch_df |>
mutate(is_hit = factor(
ifelse(popularity >= hit_threshold, "hit", "nonhit"),
levels = c("hit", "nonhit")))
# double checking distribution of hit songs
table(enoch_df$is_hit)
prop.table(table(enoch_df$is_hit))
# split data into training and test data (80/20)
set.seed(123)
train_index <- createDataPartition(enoch_df$is_hit, p = 0.8, list = FALSE)
train <- enoch_df[train_index, ]
test <- enoch_df[-train_index, ]
train_small <- train |>
group_by(is_hit) |>
sample_frac(0.20) |>
ungroup()
# normalizing numeric features
preprocess_parms <- preProcess(train |>
select_if(is.numeric),
method = c("center", "scale"))
train <- predict(preprocess_parms, train)
test <- predict(preprocess_parms, test)
train$is_hit <- relevel(train$is_hit, ref = "hit")
test$is_hit <- relevel(test$is_hit, ref = "hit")
# METHOD 1: logistic regression model creation
logis_model <- glm(is_hit ~ danceability + energy + loudness + valence +
tempo + speechiness + liveness + instrumentalness +
acousticness + duration_ms, data = log_train, family = "binomial")
# create my own dataset to use for this analysis
enoch_df <- spotify_data
# creating "is_hit" column by calculating 90th percentile of popularity
hit_threshold <- quantile(enoch_df$popularity, probs = 0.90)
# create binary target
enoch_df <- enoch_df |>
mutate(is_hit = factor(
ifelse(popularity >= hit_threshold, "hit", "nonhit"),
levels = c("hit", "nonhit")))
# double checking distribution of hit songs
table(enoch_df$is_hit)
prop.table(table(enoch_df$is_hit))
# split data into training and test data (80/20)
set.seed(123)
train_index <- createDataPartition(enoch_df$is_hit, p = 0.8, list = FALSE)
train <- enoch_df[train_index, ]
test <- enoch_df[-train_index, ]
train_small <- train |>
group_by(is_hit) |>
sample_frac(0.20) |>
ungroup()
# normalizing numeric features
preprocess_parms <- preProcess(train |>
select_if(is.numeric),
method = c("center", "scale"))
train <- predict(preprocess_parms, train)
test <- predict(preprocess_parms, test)
train$is_hit <- relevel(train$is_hit, ref = "hit")
test$is_hit <- relevel(test$is_hit, ref = "hit")
# METHOD 1: logistic regression model creation
logis_model <- glm(is_hit ~ danceability + energy + loudness + valence +
tempo + speechiness + liveness + instrumentalness +
acousticness + duration_ms, data = log_train, family = "binomial")
# create my own dataset to use for this analysis
enoch_df <- spotify_data
# creating "is_hit" column by calculating 90th percentile of popularity
hit_threshold <- quantile(enoch_df$popularity, probs = 0.90)
# create binary target
enoch_df <- enoch_df |>
mutate(is_hit = factor(
ifelse(popularity >= hit_threshold, "hit", "nonhit"),
levels = c("hit", "nonhit")))
# double checking distribution of hit songs
table(enoch_df$is_hit)
prop.table(table(enoch_df$is_hit))
# split data into training and test data (80/20)
set.seed(123)
train_index <- createDataPartition(enoch_df$is_hit, p = 0.8, list = FALSE)
train <- enoch_df[train_index, ]
test <- enoch_df[-train_index, ]
train_small <- train |>
group_by(is_hit) |>
sample_frac(0.20) |>
ungroup()
# normalizing numeric features
preprocess_parms <- preProcess(train |>
select_if(is.numeric),
method = c("center", "scale"))
train <- predict(preprocess_parms, train)
test <- predict(preprocess_parms, test)
train$is_hit <- relevel(train$is_hit, ref = "hit")
test$is_hit <- relevel(test$is_hit, ref = "hit")
# METHOD 1: logistic regression model creation
logis_model <- glm(is_hit ~ danceability + energy + loudness + valence +
tempo + speechiness + liveness + instrumentalness +
acousticness + duration_ms, data = train_small, family = "binomial")
summary(logis_model)
# predict on test set
logis_pred <- predict(logis_model, newdata = test, type = "response")
logis_pred_class <- ifelse(logis_pred > 0.5, 1, 0)
# confusion matrix
confusionMatrix(factor(logis_pred_class), test$is_hit)
# METHOD 2: categorical classification models
# CROSS-VALIDATION CONTROL
knn_ctrl <- trainControl(method = "cv",
number = 5,
savePredictions = "final")
# kNN  (tuning k)
set.seed(123)
knn_grid <- expand.grid(k = seq(3, 25, by = 2))
knn_fit <- train(is_hit ~ danceability + energy + loudness + valence +
tempo + speechiness + liveness + instrumentalness +
acousticness + duration_ms,
data = train_small,
method = "knn",
trControl = knn_ctrl,
tuneGrid  = knn_grid,
metric    = "Accuracy")
# best k and cross-validated accuracy
print(knn_fit$bestTune)
print(max(knn_fit$results$Accuracy))
# test-set accuracy
knn_pred <- predict(knn_fit, newdata = test)
knn_cm   <- confusionMatrix(knn_pred, test$is_hit, positive = "hit")
cat("\nTest accuracy (k-NN):",
round(knn_cm$overall["Accuracy"], 3), "\n")
# visualizing the results
ggplot(knn_fit$results, aes(k, Accuracy)) +
geom_line() +
geom_point(size = 2) +
geom_vline(xintercept = knn_fit$bestTune$k,
linetype = "dashed") +
labs(title = "Cross-validated accuracy across k values",
x = "Number of neighbours (k)",
y = "Accuracy") +
theme_minimal()
# Decision tree  (tuning max depth)
# "hit" is the second level, which is what twoClassSummary expects
train$is_hit <- factor(train$is_hit, levels = c("nonhit", "hit"))
test$is_hit <- factor(test$is_hit, levels = c("nonhit", "hit"))
# cross-validation set up
dt_ctrl <- trainControl(
method          = "cv",
number          = 5,
classProbs      = TRUE,
summaryFunction = twoClassSummary,
sampling        = "down",
savePredictions = "final"
)
tree_grid <- expand.grid(
cp = 10 ^ seq(-4, -1, length.out = 10)
)
set.seed(123)
tree_fit <- train(is_hit ~ danceability + energy + loudness + valence +
tempo + speechiness + liveness + instrumentalness +
acousticness + duration_ms,
data = train,
method = "rpart",      # allows maxdepth tuning
trControl = dt_ctrl,
tuneGrid  = tree_grid,
metric    = "ROC",
control = rpart.control(cp = 0,
minsplit = 2,
minbucket = 1)
)
# best depth and cross-validated accuracy
print(tree_fit$bestTune)
print(max(tree_fit$results$ROC))
prob_test <- predict(tree_fit, test, type = "prob")[ , "hit"]
pred_test <- factor(ifelse(prob_test > 0.5, "hit", "nonhit"),
levels = c("nonhit", "hit"))
cm  <- confusionMatrix(pred_test, test$is_hit)
auc <- roc(test$is_hit, prob_test, levels = c("nonhit", "hit"))$auc
cat("\nTest accuracy :", round(cm$overall["Accuracy"], 3),
"\nTest ROC-AUC  :", round(auc, 3), "\n")
# Optional: view the pruned tree
library(rpart.plot)
rpart.plot(tree_fit$finalModel,
type  = 4,      # tidy boxes
extra = 104,    # show class and % of hits
main  = "Best Decision Tree (cp tuned, down-sampled)")
# METHOD 1: logistic regression model creation
logis_model <- glm(is_hit ~ danceability + energy + loudness + valence +
tempo + speechiness + liveness + instrumentalness +
acousticness + duration_ms, data = train_small, family = "binomial")
summary(logis_model)
# predict on test set
logis_pred <- predict(logis_model, newdata = test, type = "response")
logis_pred_class <- ifelse(logis_pred > 0.5, 1, 0)
# confusion matrix
confusionMatrix(factor(logis_pred_class), test$is_hit)
